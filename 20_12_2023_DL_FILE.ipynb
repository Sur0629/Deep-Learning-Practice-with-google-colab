{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8u-RwrzkRWJB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('https://raw.githubusercontent.com/ubaid-shah/datasets/main/heart.csv')"
      ],
      "metadata": {
        "id": "BCCizb3ZS-ep"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LuaKUS0iTREt",
        "outputId": "8b047e80-6ccc-4c5e-aae1-065ef0eadd86"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
              "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
              "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
              "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
              "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   2     3       0  \n",
              "1   0     3       0  \n",
              "2   0     3       0  \n",
              "3   1     3       0  \n",
              "4   3     2       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d989c200-6f99-4738-8bcd-92cf7b8ea3e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>212</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>203</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>148</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>161</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>294</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d989c200-6f99-4738-8bcd-92cf7b8ea3e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d989c200-6f99-4738-8bcd-92cf7b8ea3e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d989c200-6f99-4738-8bcd-92cf7b8ea3e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2118c31c-c67d-413a-8115-b5ee41efe10d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2118c31c-c67d-413a-8115-b5ee41efe10d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2118c31c-c67d-413a-8115-b5ee41efe10d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5DgQwBxTsYZ",
        "outputId": "1c530720-79e3-4f2d-9202-0835ab61840f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1025, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaYM2RBdTu0n",
        "outputId": "0c2e66cb-f0fe-4e04-f112-d72240e62ca1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1025 entries, 0 to 1024\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       1025 non-null   int64  \n",
            " 1   sex       1025 non-null   int64  \n",
            " 2   cp        1025 non-null   int64  \n",
            " 3   trestbps  1025 non-null   int64  \n",
            " 4   chol      1025 non-null   int64  \n",
            " 5   fbs       1025 non-null   int64  \n",
            " 6   restecg   1025 non-null   int64  \n",
            " 7   thalach   1025 non-null   int64  \n",
            " 8   exang     1025 non-null   int64  \n",
            " 9   oldpeak   1025 non-null   float64\n",
            " 10  slope     1025 non-null   int64  \n",
            " 11  ca        1025 non-null   int64  \n",
            " 12  thal      1025 non-null   int64  \n",
            " 13  target    1025 non-null   int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 112.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.target.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpyaUDmrTyfv",
        "outputId": "e9bced5b-83e4-4750-aee6-7366b4b1569f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IBPSIMmT7DB",
        "outputId": "3b5a84b8-dd95-4652-88a1-c864bf902cff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age         0\n",
              "sex         0\n",
              "cp          0\n",
              "trestbps    0\n",
              "chol        0\n",
              "fbs         0\n",
              "restecg     0\n",
              "thalach     0\n",
              "exang       0\n",
              "oldpeak     0\n",
              "slope       0\n",
              "ca          0\n",
              "thal        0\n",
              "target      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X=df.drop('target',axis=1)\n",
        "y=df.target\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "HfwkEz3jT-PV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Js_ZU-mUDZ0",
        "outputId": "55f1935a-9bad-4e00-a9e3-c7fc12b53150"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1i3QvhiUQV1",
        "outputId": "4da14fe4-30f5-49a3-c7f5-0a496d4745d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(820,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK4TfXzDUSHo",
        "outputId": "ea0b9f03-2d9d-4731-9be1-24fe37bd6614"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(205,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVblkNmwUT2s",
        "outputId": "65667a9f-1fa0-4d1a-8a8d-a5638d6bd8ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(205, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Logistic Regression"
      ],
      "metadata": {
        "id": "oGnC_VM9UY-C"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "Lx3d_sLfUns_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=LogisticRegression()"
      ],
      "metadata": {
        "id": "VTnXY2-kUqF0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "wvesMV25UrqX",
        "outputId": "75f46345-e360-41c5-89b2-1b1745a76df2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=lr.predict(X_test)"
      ],
      "metadata": {
        "id": "FhyDoMvDUwJU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print('the accuracy of the model is : ', round(accuracy_score(y_test,y_pred),2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP66zqcoUxbx",
        "outputId": "ecdd279a-dba2-4921-e897-259dc253acd3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the accuracy of the model is :  0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Neural Network"
      ],
      "metadata": {
        "id": "FV6mTxDrU07a"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " ! pip install  tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7bRpx8_U4W8",
        "outputId": "b93343e4-f879-44f6-91f6-4b26fb41363d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "BNdUXc-zU7on"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(11,activation='relu',input_dim=X_train.shape[1]))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "099GMZfJU_fx",
        "outputId": "26df7128-dce7-4844-bc63-63da4a273729"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 11)                154       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 12        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 166 (664.00 Byte)\n",
            "Trainable params: 166 (664.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EP_mRTtVDVI",
        "outputId": "98a53d9b-9bb1-468f-8ec7-14e8fd8ee217"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "26/26 [==============================] - 2s 9ms/step - loss: 18.1708 - accuracy: 0.4890\n",
            "Epoch 2/300\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 6.0127 - accuracy: 0.4171\n",
            "Epoch 3/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 3.2337 - accuracy: 0.4049\n",
            "Epoch 4/300\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.6409 - accuracy: 0.4024\n",
            "Epoch 5/300\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 2.2036 - accuracy: 0.4390\n",
            "Epoch 6/300\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 1.7657 - accuracy: 0.4756\n",
            "Epoch 7/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1.4329 - accuracy: 0.4841\n",
            "Epoch 8/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1.2360 - accuracy: 0.5293\n",
            "Epoch 9/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1.1373 - accuracy: 0.5610\n",
            "Epoch 10/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.0436 - accuracy: 0.5927\n",
            "Epoch 11/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.9838 - accuracy: 0.6049\n",
            "Epoch 12/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.9381 - accuracy: 0.6098\n",
            "Epoch 13/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9062 - accuracy: 0.6244\n",
            "Epoch 14/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.8849 - accuracy: 0.6354\n",
            "Epoch 15/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8591 - accuracy: 0.6427\n",
            "Epoch 16/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8319 - accuracy: 0.6439\n",
            "Epoch 17/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8152 - accuracy: 0.6549\n",
            "Epoch 18/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7987 - accuracy: 0.6524\n",
            "Epoch 19/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7775 - accuracy: 0.6744\n",
            "Epoch 20/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.7728 - accuracy: 0.6634\n",
            "Epoch 21/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7531 - accuracy: 0.6829\n",
            "Epoch 22/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7285 - accuracy: 0.6768\n",
            "Epoch 23/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.7149 - accuracy: 0.6927\n",
            "Epoch 24/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7068 - accuracy: 0.6805\n",
            "Epoch 25/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.6878\n",
            "Epoch 26/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.7024\n",
            "Epoch 27/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.6915\n",
            "Epoch 28/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.7012\n",
            "Epoch 29/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.7110\n",
            "Epoch 30/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.7098\n",
            "Epoch 31/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.7293\n",
            "Epoch 32/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.7207\n",
            "Epoch 33/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7220\n",
            "Epoch 34/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7207\n",
            "Epoch 35/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7415\n",
            "Epoch 36/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7232\n",
            "Epoch 37/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7354\n",
            "Epoch 38/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7305\n",
            "Epoch 39/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7439\n",
            "Epoch 40/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7317\n",
            "Epoch 41/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7439\n",
            "Epoch 42/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7524\n",
            "Epoch 43/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7610\n",
            "Epoch 44/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7585\n",
            "Epoch 45/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7610\n",
            "Epoch 46/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7634\n",
            "Epoch 47/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7598\n",
            "Epoch 48/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7622\n",
            "Epoch 49/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7841\n",
            "Epoch 50/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7646\n",
            "Epoch 51/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7793\n",
            "Epoch 52/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7756\n",
            "Epoch 53/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7732\n",
            "Epoch 54/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7866\n",
            "Epoch 55/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7805\n",
            "Epoch 56/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7976\n",
            "Epoch 57/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7963\n",
            "Epoch 58/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7951\n",
            "Epoch 59/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8049\n",
            "Epoch 60/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8024\n",
            "Epoch 61/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8012\n",
            "Epoch 62/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7939\n",
            "Epoch 63/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8110\n",
            "Epoch 64/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8183\n",
            "Epoch 65/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8110\n",
            "Epoch 66/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8146\n",
            "Epoch 67/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8061\n",
            "Epoch 68/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7976\n",
            "Epoch 69/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8171\n",
            "Epoch 70/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8232\n",
            "Epoch 71/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8098\n",
            "Epoch 72/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8220\n",
            "Epoch 73/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8183\n",
            "Epoch 74/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8280\n",
            "Epoch 75/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8268\n",
            "Epoch 76/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8305\n",
            "Epoch 77/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8280\n",
            "Epoch 78/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8232\n",
            "Epoch 79/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8171\n",
            "Epoch 80/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8354\n",
            "Epoch 81/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8439\n",
            "Epoch 82/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8195\n",
            "Epoch 83/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8366\n",
            "Epoch 84/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8293\n",
            "Epoch 85/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8378\n",
            "Epoch 86/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8256\n",
            "Epoch 87/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8268\n",
            "Epoch 88/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8329\n",
            "Epoch 89/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8427\n",
            "Epoch 90/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8378\n",
            "Epoch 91/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8244\n",
            "Epoch 92/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8415\n",
            "Epoch 93/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8244\n",
            "Epoch 94/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8171\n",
            "Epoch 95/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8354\n",
            "Epoch 96/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8402\n",
            "Epoch 97/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8476\n",
            "Epoch 98/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8402\n",
            "Epoch 99/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8427\n",
            "Epoch 100/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8329\n",
            "Epoch 101/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8317\n",
            "Epoch 102/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8439\n",
            "Epoch 103/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8378\n",
            "Epoch 104/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8512\n",
            "Epoch 105/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8415\n",
            "Epoch 106/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8317\n",
            "Epoch 107/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8354\n",
            "Epoch 108/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8293\n",
            "Epoch 109/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8390\n",
            "Epoch 110/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8402\n",
            "Epoch 111/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8378\n",
            "Epoch 112/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8378\n",
            "Epoch 113/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8463\n",
            "Epoch 114/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8439\n",
            "Epoch 115/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8329\n",
            "Epoch 116/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8439\n",
            "Epoch 117/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8488\n",
            "Epoch 118/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8415\n",
            "Epoch 119/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8256\n",
            "Epoch 120/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8280\n",
            "Epoch 121/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8415\n",
            "Epoch 122/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8366\n",
            "Epoch 123/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8427\n",
            "Epoch 124/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8476\n",
            "Epoch 125/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8476\n",
            "Epoch 126/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8329\n",
            "Epoch 127/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8549\n",
            "Epoch 128/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8390\n",
            "Epoch 129/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8476\n",
            "Epoch 130/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8329\n",
            "Epoch 131/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8244\n",
            "Epoch 132/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8232\n",
            "Epoch 133/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8476\n",
            "Epoch 134/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8427\n",
            "Epoch 135/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8293\n",
            "Epoch 136/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8329\n",
            "Epoch 137/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8317\n",
            "Epoch 138/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8354\n",
            "Epoch 139/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8390\n",
            "Epoch 140/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8402\n",
            "Epoch 141/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8500\n",
            "Epoch 142/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8378\n",
            "Epoch 143/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8341\n",
            "Epoch 144/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8305\n",
            "Epoch 145/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8171\n",
            "Epoch 146/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8366\n",
            "Epoch 147/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8305\n",
            "Epoch 148/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8402\n",
            "Epoch 149/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8524\n",
            "Epoch 150/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8476\n",
            "Epoch 151/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8524\n",
            "Epoch 152/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8524\n",
            "Epoch 153/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8524\n",
            "Epoch 154/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8512\n",
            "Epoch 155/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8537\n",
            "Epoch 156/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8402\n",
            "Epoch 157/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3623 - accuracy: 0.8488\n",
            "Epoch 158/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8561\n",
            "Epoch 159/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8512\n",
            "Epoch 160/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8463\n",
            "Epoch 161/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8463\n",
            "Epoch 162/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8329\n",
            "Epoch 163/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8476\n",
            "Epoch 164/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8500\n",
            "Epoch 165/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8280\n",
            "Epoch 166/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8500\n",
            "Epoch 167/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8415\n",
            "Epoch 168/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8451\n",
            "Epoch 169/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8354\n",
            "Epoch 170/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8427\n",
            "Epoch 171/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8439\n",
            "Epoch 172/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8537\n",
            "Epoch 173/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8341\n",
            "Epoch 174/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8488\n",
            "Epoch 175/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8415\n",
            "Epoch 176/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8476\n",
            "Epoch 177/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8415\n",
            "Epoch 178/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8402\n",
            "Epoch 179/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8451\n",
            "Epoch 180/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3601 - accuracy: 0.8549\n",
            "Epoch 181/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3694 - accuracy: 0.8439\n",
            "Epoch 182/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3623 - accuracy: 0.8476\n",
            "Epoch 183/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8280\n",
            "Epoch 184/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8293\n",
            "Epoch 185/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8402\n",
            "Epoch 186/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8305\n",
            "Epoch 187/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.8512\n",
            "Epoch 188/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3652 - accuracy: 0.8451\n",
            "Epoch 189/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.8512\n",
            "Epoch 190/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8549\n",
            "Epoch 191/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8366\n",
            "Epoch 192/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3610 - accuracy: 0.8598\n",
            "Epoch 193/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8439\n",
            "Epoch 194/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8280\n",
            "Epoch 195/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8524\n",
            "Epoch 196/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.8500\n",
            "Epoch 197/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8451\n",
            "Epoch 198/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8585\n",
            "Epoch 199/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8476\n",
            "Epoch 200/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8390\n",
            "Epoch 201/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8451\n",
            "Epoch 202/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8366\n",
            "Epoch 203/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3774 - accuracy: 0.8500\n",
            "Epoch 204/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8293\n",
            "Epoch 205/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8366\n",
            "Epoch 206/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8500\n",
            "Epoch 207/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3610 - accuracy: 0.8476\n",
            "Epoch 208/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8451\n",
            "Epoch 209/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8463\n",
            "Epoch 210/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8451\n",
            "Epoch 211/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8537\n",
            "Epoch 212/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8537\n",
            "Epoch 213/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8427\n",
            "Epoch 214/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8402\n",
            "Epoch 215/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8476\n",
            "Epoch 216/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8439\n",
            "Epoch 217/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8293\n",
            "Epoch 218/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8476\n",
            "Epoch 219/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3634 - accuracy: 0.8512\n",
            "Epoch 220/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8463\n",
            "Epoch 221/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8476\n",
            "Epoch 222/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8402\n",
            "Epoch 223/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8451\n",
            "Epoch 224/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.8476\n",
            "Epoch 225/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8476\n",
            "Epoch 226/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8305\n",
            "Epoch 227/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8305\n",
            "Epoch 228/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8537\n",
            "Epoch 229/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8268\n",
            "Epoch 230/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8561\n",
            "Epoch 231/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8390\n",
            "Epoch 232/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8390\n",
            "Epoch 233/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8549\n",
            "Epoch 234/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8427\n",
            "Epoch 235/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8463\n",
            "Epoch 236/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8573\n",
            "Epoch 237/300\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.3593 - accuracy: 0.8512\n",
            "Epoch 238/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8488\n",
            "Epoch 239/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3620 - accuracy: 0.8500\n",
            "Epoch 240/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8341\n",
            "Epoch 241/300\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8220\n",
            "Epoch 242/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8390\n",
            "Epoch 243/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8329\n",
            "Epoch 244/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8439\n",
            "Epoch 245/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8439\n",
            "Epoch 246/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8500\n",
            "Epoch 247/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3704 - accuracy: 0.8317\n",
            "Epoch 248/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8500\n",
            "Epoch 249/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3595 - accuracy: 0.8451\n",
            "Epoch 250/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8451\n",
            "Epoch 251/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8500\n",
            "Epoch 252/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3601 - accuracy: 0.8634\n",
            "Epoch 253/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3660 - accuracy: 0.8500\n",
            "Epoch 254/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3585 - accuracy: 0.8427\n",
            "Epoch 255/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8500\n",
            "Epoch 256/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3576 - accuracy: 0.8512\n",
            "Epoch 257/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8366\n",
            "Epoch 258/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8427\n",
            "Epoch 259/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8488\n",
            "Epoch 260/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8354\n",
            "Epoch 261/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8463\n",
            "Epoch 262/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3614 - accuracy: 0.8439\n",
            "Epoch 263/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.8451\n",
            "Epoch 264/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3601 - accuracy: 0.8427\n",
            "Epoch 265/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3632 - accuracy: 0.8280\n",
            "Epoch 266/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3561 - accuracy: 0.8476\n",
            "Epoch 267/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8451\n",
            "Epoch 268/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.8427\n",
            "Epoch 269/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8488\n",
            "Epoch 270/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3692 - accuracy: 0.8415\n",
            "Epoch 271/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8366\n",
            "Epoch 272/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3627 - accuracy: 0.8488\n",
            "Epoch 273/300\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.3609 - accuracy: 0.8500\n",
            "Epoch 274/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3646 - accuracy: 0.8512\n",
            "Epoch 275/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8463\n",
            "Epoch 276/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.8354\n",
            "Epoch 277/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8476\n",
            "Epoch 278/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8500\n",
            "Epoch 279/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8402\n",
            "Epoch 280/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8537\n",
            "Epoch 281/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8524\n",
            "Epoch 282/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3623 - accuracy: 0.8476\n",
            "Epoch 283/300\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.3573 - accuracy: 0.8512\n",
            "Epoch 284/300\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8329\n",
            "Epoch 285/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3570 - accuracy: 0.8451\n",
            "Epoch 286/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8220\n",
            "Epoch 287/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3574 - accuracy: 0.8402\n",
            "Epoch 288/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.8573\n",
            "Epoch 289/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8378\n",
            "Epoch 290/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8549\n",
            "Epoch 291/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8500\n",
            "Epoch 292/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8439\n",
            "Epoch 293/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3547 - accuracy: 0.8402\n",
            "Epoch 294/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8451\n",
            "Epoch 295/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8512\n",
            "Epoch 296/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8415\n",
            "Epoch 297/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8451\n",
            "Epoch 298/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8512\n",
            "Epoch 299/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8561\n",
            "Epoch 300/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8476\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bacae74f7c0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_nn=model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7255naKVIJ1",
        "outputId": "f5153e6f-66d4-4c44-c67b-e73186248003"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_nn[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4VfW_vIVN6S",
        "outputId": "420942f1-af29-4915-ee68-d9e8d4c5d087"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.89761275"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_n1=[round(x[0]) for x in y_pred_nn]"
      ],
      "metadata": {
        "id": "raq9GfIvVPl0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_n1[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPMfaOsXVRHJ",
        "outputId": "785ecd12-fee0-44b2-91d4-cc499c294dd0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKCBFkoCVVJs",
        "outputId": "27dca6d1-d4b4-4840-ac37-08e3dfb01f7c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "807    1\n",
              "27     0\n",
              "77     0\n",
              "406    1\n",
              "886    0\n",
              "      ..\n",
              "877    1\n",
              "320    1\n",
              "362    1\n",
              "452    0\n",
              "500    1\n",
              "Name: target, Length: 205, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The accuracy of the shallow neural net is :', round(accuracy_score(y_test,y_pred_n1),2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeMV3HPwVX5r",
        "outputId": "2307c88b-dff8-48b2-c00c-4ecfc63a5f13"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the shallow neural net is : 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(11,activation='relu',input_dim=X_train.shape[1]))\n",
        "model.add(Dense(5,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(X_train,y_train,epochs=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IwNFK0DVaGn",
        "outputId": "791a915f-bad1-488c-ad33-6b6f8a9889df"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 11)                154       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 60        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 220 (880.00 Byte)\n",
            "Trainable params: 220 (880.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "26/26 [==============================] - 1s 4ms/step - loss: 16.9445 - accuracy: 0.4890\n",
            "Epoch 2/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 3.9953 - accuracy: 0.4939\n",
            "Epoch 3/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1.0897 - accuracy: 0.5634\n",
            "Epoch 4/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.7457 - accuracy: 0.6024\n",
            "Epoch 5/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.7144 - accuracy: 0.6110\n",
            "Epoch 6/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7092 - accuracy: 0.6220\n",
            "Epoch 7/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.6122\n",
            "Epoch 8/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.6049\n",
            "Epoch 9/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.6000\n",
            "Epoch 10/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.6000\n",
            "Epoch 11/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.6061\n",
            "Epoch 12/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.5963\n",
            "Epoch 13/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.5939\n",
            "Epoch 14/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.5963\n",
            "Epoch 15/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.5878\n",
            "Epoch 16/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.5866\n",
            "Epoch 17/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.5878\n",
            "Epoch 18/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.5878\n",
            "Epoch 19/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.5866\n",
            "Epoch 20/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.5902\n",
            "Epoch 21/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.5915\n",
            "Epoch 22/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.5927\n",
            "Epoch 23/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.5927\n",
            "Epoch 24/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.5927\n",
            "Epoch 25/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.5963\n",
            "Epoch 26/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.5939\n",
            "Epoch 27/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.5963\n",
            "Epoch 28/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6000\n",
            "Epoch 29/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.6000\n",
            "Epoch 30/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.6000\n",
            "Epoch 31/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.6000\n",
            "Epoch 32/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.6037\n",
            "Epoch 33/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.6037\n",
            "Epoch 34/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.6000\n",
            "Epoch 35/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.6037\n",
            "Epoch 36/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.6000\n",
            "Epoch 37/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6110\n",
            "Epoch 38/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6110\n",
            "Epoch 39/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6024\n",
            "Epoch 40/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6110\n",
            "Epoch 41/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.6037\n",
            "Epoch 42/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.6073\n",
            "Epoch 43/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.6098\n",
            "Epoch 44/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.6171\n",
            "Epoch 45/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6000\n",
            "Epoch 46/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.6122\n",
            "Epoch 47/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.6122\n",
            "Epoch 48/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.6146\n",
            "Epoch 49/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6122\n",
            "Epoch 50/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6110\n",
            "Epoch 51/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.6085\n",
            "Epoch 52/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.6122\n",
            "Epoch 53/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6122\n",
            "Epoch 54/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6146\n",
            "Epoch 55/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6183\n",
            "Epoch 56/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.6183\n",
            "Epoch 57/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.6110\n",
            "Epoch 58/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6134\n",
            "Epoch 59/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.6146\n",
            "Epoch 60/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6085\n",
            "Epoch 61/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6122\n",
            "Epoch 62/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6159\n",
            "Epoch 63/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.6110\n",
            "Epoch 64/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.6122\n",
            "Epoch 65/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.6061\n",
            "Epoch 66/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6195\n",
            "Epoch 67/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 0.6159\n",
            "Epoch 68/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6159\n",
            "Epoch 69/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.6146\n",
            "Epoch 70/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.6049\n",
            "Epoch 71/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.6146\n",
            "Epoch 72/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.6159\n",
            "Epoch 73/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6134\n",
            "Epoch 74/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6284 - accuracy: 0.6134\n",
            "Epoch 75/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.6183\n",
            "Epoch 76/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6122\n",
            "Epoch 77/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6271 - accuracy: 0.6146\n",
            "Epoch 78/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6110\n",
            "Epoch 79/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.6183\n",
            "Epoch 80/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.6110\n",
            "Epoch 81/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.6159\n",
            "Epoch 82/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.6110\n",
            "Epoch 83/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.6159\n",
            "Epoch 84/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.6171\n",
            "Epoch 85/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.6159\n",
            "Epoch 86/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.6159\n",
            "Epoch 87/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.6159\n",
            "Epoch 88/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.6220\n",
            "Epoch 89/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6232\n",
            "Epoch 90/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.6061\n",
            "Epoch 91/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.6232\n",
            "Epoch 92/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6122\n",
            "Epoch 93/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6195\n",
            "Epoch 94/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.6061\n",
            "Epoch 95/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6225 - accuracy: 0.6244\n",
            "Epoch 96/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6239 - accuracy: 0.6207\n",
            "Epoch 97/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.6171\n",
            "Epoch 98/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6212 - accuracy: 0.6159\n",
            "Epoch 99/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.6207\n",
            "Epoch 100/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.6183\n",
            "Epoch 101/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6256 - accuracy: 0.6220\n",
            "Epoch 102/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6171\n",
            "Epoch 103/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.6207\n",
            "Epoch 104/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.6146\n",
            "Epoch 105/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.6073\n",
            "Epoch 106/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6183\n",
            "Epoch 107/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.6293\n",
            "Epoch 108/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6201 - accuracy: 0.6220\n",
            "Epoch 109/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.6256\n",
            "Epoch 110/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.6159\n",
            "Epoch 111/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.6195\n",
            "Epoch 112/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.6146\n",
            "Epoch 113/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.6293\n",
            "Epoch 114/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6207\n",
            "Epoch 115/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6305\n",
            "Epoch 116/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6280\n",
            "Epoch 117/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6171\n",
            "Epoch 118/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.6280\n",
            "Epoch 119/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6317\n",
            "Epoch 120/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.6268\n",
            "Epoch 121/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6390\n",
            "Epoch 122/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.6329\n",
            "Epoch 123/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6256\n",
            "Epoch 124/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6317\n",
            "Epoch 125/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.6305\n",
            "Epoch 126/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6146\n",
            "Epoch 127/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6354\n",
            "Epoch 128/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.6341\n",
            "Epoch 129/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.6354\n",
            "Epoch 130/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6390\n",
            "Epoch 131/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.6427\n",
            "Epoch 132/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.6390\n",
            "Epoch 133/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6329\n",
            "Epoch 134/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.6415\n",
            "Epoch 135/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.6390\n",
            "Epoch 136/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.6402\n",
            "Epoch 137/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.6293\n",
            "Epoch 138/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.6354\n",
            "Epoch 139/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.6366\n",
            "Epoch 140/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6390\n",
            "Epoch 141/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.6378\n",
            "Epoch 142/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.6390\n",
            "Epoch 143/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.6476\n",
            "Epoch 144/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6145 - accuracy: 0.6268\n",
            "Epoch 145/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.6439\n",
            "Epoch 146/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6476\n",
            "Epoch 147/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.6341\n",
            "Epoch 148/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.6512\n",
            "Epoch 149/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6512\n",
            "Epoch 150/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6439\n",
            "Epoch 151/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.6390\n",
            "Epoch 152/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.6537\n",
            "Epoch 153/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6402\n",
            "Epoch 154/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.6512\n",
            "Epoch 155/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6439\n",
            "Epoch 156/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.6451\n",
            "Epoch 157/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.6378\n",
            "Epoch 158/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6476\n",
            "Epoch 159/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.6378\n",
            "Epoch 160/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6415\n",
            "Epoch 161/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6512\n",
            "Epoch 162/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.6451\n",
            "Epoch 163/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.6549\n",
            "Epoch 164/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6512\n",
            "Epoch 165/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.6451\n",
            "Epoch 166/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.6500\n",
            "Epoch 167/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6488\n",
            "Epoch 168/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.6463\n",
            "Epoch 169/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.6488\n",
            "Epoch 170/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.6488\n",
            "Epoch 171/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6488\n",
            "Epoch 172/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.6549\n",
            "Epoch 173/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.6439\n",
            "Epoch 174/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.6500\n",
            "Epoch 175/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.6561\n",
            "Epoch 176/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.6476\n",
            "Epoch 177/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.6488\n",
            "Epoch 178/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.6512\n",
            "Epoch 179/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.6573\n",
            "Epoch 180/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6488\n",
            "Epoch 181/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.6537\n",
            "Epoch 182/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5913 - accuracy: 0.6463\n",
            "Epoch 183/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.6524\n",
            "Epoch 184/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.6573\n",
            "Epoch 185/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.6598\n",
            "Epoch 186/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.6598\n",
            "Epoch 187/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6659\n",
            "Epoch 188/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.6598\n",
            "Epoch 189/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.6671\n",
            "Epoch 190/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.6585\n",
            "Epoch 191/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.6598\n",
            "Epoch 192/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.6683\n",
            "Epoch 193/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.6732\n",
            "Epoch 194/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.6659\n",
            "Epoch 195/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.6537\n",
            "Epoch 196/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.6756\n",
            "Epoch 197/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.6732\n",
            "Epoch 198/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.6780\n",
            "Epoch 199/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.6744\n",
            "Epoch 200/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.6805\n",
            "Epoch 201/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.6793\n",
            "Epoch 202/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.6817\n",
            "Epoch 203/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.6683\n",
            "Epoch 204/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.6854\n",
            "Epoch 205/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.6878\n",
            "Epoch 206/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.6829\n",
            "Epoch 207/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.6841\n",
            "Epoch 208/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.6878\n",
            "Epoch 209/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7024\n",
            "Epoch 210/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.6866\n",
            "Epoch 211/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7024\n",
            "Epoch 212/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7049\n",
            "Epoch 213/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7098\n",
            "Epoch 214/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.6951\n",
            "Epoch 215/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7146\n",
            "Epoch 216/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7110\n",
            "Epoch 217/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.7110\n",
            "Epoch 218/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.7049\n",
            "Epoch 219/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7159\n",
            "Epoch 220/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7146\n",
            "Epoch 221/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7207\n",
            "Epoch 222/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7341\n",
            "Epoch 223/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7195\n",
            "Epoch 224/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7317\n",
            "Epoch 225/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7183\n",
            "Epoch 226/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7305\n",
            "Epoch 227/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7293\n",
            "Epoch 228/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7329\n",
            "Epoch 229/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7305\n",
            "Epoch 230/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7220\n",
            "Epoch 231/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7244\n",
            "Epoch 232/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7378\n",
            "Epoch 233/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7415\n",
            "Epoch 234/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7439\n",
            "Epoch 235/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7488\n",
            "Epoch 236/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7512\n",
            "Epoch 237/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7780\n",
            "Epoch 238/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7817\n",
            "Epoch 239/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.7780\n",
            "Epoch 240/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7829\n",
            "Epoch 241/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7951\n",
            "Epoch 242/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4739 - accuracy: 0.7878\n",
            "Epoch 243/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7927\n",
            "Epoch 244/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.8024\n",
            "Epoch 245/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.8073\n",
            "Epoch 246/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7878\n",
            "Epoch 247/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.8037\n",
            "Epoch 248/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.8098\n",
            "Epoch 249/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8159\n",
            "Epoch 250/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.8159\n",
            "Epoch 251/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.8122\n",
            "Epoch 252/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.8134\n",
            "Epoch 253/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.8061\n",
            "Epoch 254/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8220\n",
            "Epoch 255/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.8220\n",
            "Epoch 256/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.8244\n",
            "Epoch 257/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8134\n",
            "Epoch 258/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8146\n",
            "Epoch 259/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8195\n",
            "Epoch 260/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8220\n",
            "Epoch 261/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8268\n",
            "Epoch 262/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8232\n",
            "Epoch 263/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8220\n",
            "Epoch 264/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8232\n",
            "Epoch 265/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8195\n",
            "Epoch 266/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8268\n",
            "Epoch 267/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8268\n",
            "Epoch 268/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8232\n",
            "Epoch 269/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8256\n",
            "Epoch 270/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8207\n",
            "Epoch 271/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8220\n",
            "Epoch 272/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8256\n",
            "Epoch 273/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8171\n",
            "Epoch 274/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8293\n",
            "Epoch 275/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8354\n",
            "Epoch 276/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8280\n",
            "Epoch 277/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8134\n",
            "Epoch 278/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8256\n",
            "Epoch 279/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8110\n",
            "Epoch 280/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8256\n",
            "Epoch 281/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8256\n",
            "Epoch 282/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8293\n",
            "Epoch 283/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8341\n",
            "Epoch 284/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8244\n",
            "Epoch 285/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3927 - accuracy: 0.8378\n",
            "Epoch 286/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8134\n",
            "Epoch 287/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8280\n",
            "Epoch 288/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8293\n",
            "Epoch 289/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8305\n",
            "Epoch 290/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8232\n",
            "Epoch 291/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8305\n",
            "Epoch 292/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.8341\n",
            "Epoch 293/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8402\n",
            "Epoch 294/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8317\n",
            "Epoch 295/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8317\n",
            "Epoch 296/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3876 - accuracy: 0.8305\n",
            "Epoch 297/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8439\n",
            "Epoch 298/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8280\n",
            "Epoch 299/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8268\n",
            "Epoch 300/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8354\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bac9ed894e0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_nn1=model.predict(X_test)\n",
        "y_pred_n2=[round(x[0]) for x in y_pred_nn1]\n",
        "print('The accuracy of the deep neural net is :', round(accuracy_score(y_test,y_pred_n2),2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptrbirS7Vc31",
        "outputId": "3e8151c6-1585-48fb-d4d9-ec6e815a54fe"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step\n",
            "The accuracy of the deep neural net is : 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(11,activation='relu',input_dim=X_train.shape[1]))\n",
        "model.add(Dense(5,activation='relu'))\n",
        "model.add(Dense(5,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(X_train,y_train,epochs=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--tNMvkqVkZY",
        "outputId": "14e4f1ca-7066-4387-df4a-c0822719bfa7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 11)                154       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 5)                 60        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 250 (1000.00 Byte)\n",
            "Trainable params: 250 (1000.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "26/26 [==============================] - 1s 3ms/step - loss: 14.8671 - accuracy: 0.4890\n",
            "Epoch 2/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 6.7704 - accuracy: 0.4890\n",
            "Epoch 3/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.8278 - accuracy: 0.4890\n",
            "Epoch 4/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.8649 - accuracy: 0.4951\n",
            "Epoch 5/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7246 - accuracy: 0.5232\n",
            "Epoch 6/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7093 - accuracy: 0.5232\n",
            "Epoch 7/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.5195\n",
            "Epoch 8/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7045 - accuracy: 0.5232\n",
            "Epoch 9/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7018 - accuracy: 0.5280\n",
            "Epoch 10/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.5390\n",
            "Epoch 11/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5561\n",
            "Epoch 12/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5707\n",
            "Epoch 13/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.5720\n",
            "Epoch 14/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5756\n",
            "Epoch 15/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6744 - accuracy: 0.5720\n",
            "Epoch 16/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.5707\n",
            "Epoch 17/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.5805\n",
            "Epoch 18/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.5707\n",
            "Epoch 19/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.5707\n",
            "Epoch 20/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6615 - accuracy: 0.5707\n",
            "Epoch 21/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.5756\n",
            "Epoch 22/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.5768\n",
            "Epoch 23/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6642 - accuracy: 0.5354\n",
            "Epoch 24/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.5744\n",
            "Epoch 25/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.5817\n",
            "Epoch 26/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6605 - accuracy: 0.5744\n",
            "Epoch 27/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.5805\n",
            "Epoch 28/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.5756\n",
            "Epoch 29/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.5805\n",
            "Epoch 30/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.6566 - accuracy: 0.5732\n",
            "Epoch 31/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.5744\n",
            "Epoch 32/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.5768\n",
            "Epoch 33/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.5805\n",
            "Epoch 34/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.5768\n",
            "Epoch 35/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.5780\n",
            "Epoch 36/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6528 - accuracy: 0.5780\n",
            "Epoch 37/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.5768\n",
            "Epoch 38/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.5841\n",
            "Epoch 39/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.5744\n",
            "Epoch 40/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.5756\n",
            "Epoch 41/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.5768\n",
            "Epoch 42/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.5902\n",
            "Epoch 43/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6520 - accuracy: 0.5768\n",
            "Epoch 44/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.5878\n",
            "Epoch 45/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.5817\n",
            "Epoch 46/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.5841\n",
            "Epoch 47/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.5829\n",
            "Epoch 48/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.5854\n",
            "Epoch 49/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.5890\n",
            "Epoch 50/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.5854\n",
            "Epoch 51/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6436 - accuracy: 0.5927\n",
            "Epoch 52/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.5890\n",
            "Epoch 53/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.5915\n",
            "Epoch 54/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6446 - accuracy: 0.5951\n",
            "Epoch 55/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.5915\n",
            "Epoch 56/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.5939\n",
            "Epoch 57/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.5915\n",
            "Epoch 58/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.5927\n",
            "Epoch 59/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.5951\n",
            "Epoch 60/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.5976\n",
            "Epoch 61/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.5976\n",
            "Epoch 62/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.6000\n",
            "Epoch 63/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6000\n",
            "Epoch 64/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.5793\n",
            "Epoch 65/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.6024\n",
            "Epoch 66/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.6012\n",
            "Epoch 67/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6390 - accuracy: 0.5988\n",
            "Epoch 68/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6073\n",
            "Epoch 69/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.6037\n",
            "Epoch 70/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6061\n",
            "Epoch 71/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6098\n",
            "Epoch 72/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6171\n",
            "Epoch 73/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.6159\n",
            "Epoch 74/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6390\n",
            "Epoch 75/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6171\n",
            "Epoch 76/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6268\n",
            "Epoch 77/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6256\n",
            "Epoch 78/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.6280\n",
            "Epoch 79/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.6280\n",
            "Epoch 80/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6293\n",
            "Epoch 81/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.6415\n",
            "Epoch 82/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.6366\n",
            "Epoch 83/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.6500\n",
            "Epoch 84/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.6646\n",
            "Epoch 85/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.6707\n",
            "Epoch 86/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.6549\n",
            "Epoch 87/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.6622\n",
            "Epoch 88/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.6659\n",
            "Epoch 89/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.6610\n",
            "Epoch 90/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.6841\n",
            "Epoch 91/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.6878\n",
            "Epoch 92/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.6634\n",
            "Epoch 93/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.6622\n",
            "Epoch 94/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.7049\n",
            "Epoch 95/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.6915\n",
            "Epoch 96/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7085\n",
            "Epoch 97/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7000\n",
            "Epoch 98/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7073\n",
            "Epoch 99/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7195\n",
            "Epoch 100/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7220\n",
            "Epoch 101/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7280\n",
            "Epoch 102/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7354\n",
            "Epoch 103/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7354\n",
            "Epoch 104/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7415\n",
            "Epoch 105/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7768\n",
            "Epoch 106/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7427\n",
            "Epoch 107/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7854\n",
            "Epoch 108/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7671\n",
            "Epoch 109/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7951\n",
            "Epoch 110/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7866\n",
            "Epoch 111/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.8000\n",
            "Epoch 112/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7988\n",
            "Epoch 113/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7878\n",
            "Epoch 114/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8012\n",
            "Epoch 115/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8195\n",
            "Epoch 116/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8171\n",
            "Epoch 117/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8061\n",
            "Epoch 118/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.8110\n",
            "Epoch 119/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8220\n",
            "Epoch 120/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7890\n",
            "Epoch 121/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7988\n",
            "Epoch 122/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8073\n",
            "Epoch 123/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8183\n",
            "Epoch 124/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8159\n",
            "Epoch 125/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8378\n",
            "Epoch 126/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8171\n",
            "Epoch 127/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8220\n",
            "Epoch 128/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8439\n",
            "Epoch 129/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8171\n",
            "Epoch 130/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8024\n",
            "Epoch 131/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8488\n",
            "Epoch 132/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8280\n",
            "Epoch 133/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8293\n",
            "Epoch 134/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8341\n",
            "Epoch 135/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8122\n",
            "Epoch 136/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8183\n",
            "Epoch 137/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8341\n",
            "Epoch 138/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8159\n",
            "Epoch 139/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8549\n",
            "Epoch 140/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8220\n",
            "Epoch 141/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8451\n",
            "Epoch 142/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8463\n",
            "Epoch 143/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8280\n",
            "Epoch 144/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8268\n",
            "Epoch 145/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8366\n",
            "Epoch 146/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.8366\n",
            "Epoch 147/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8561\n",
            "Epoch 148/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8476\n",
            "Epoch 149/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8634\n",
            "Epoch 150/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8329\n",
            "Epoch 151/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3876 - accuracy: 0.8402\n",
            "Epoch 152/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3851 - accuracy: 0.8402\n",
            "Epoch 153/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3960 - accuracy: 0.8122\n",
            "Epoch 154/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8561\n",
            "Epoch 155/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8537\n",
            "Epoch 156/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8256\n",
            "Epoch 157/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8232\n",
            "Epoch 158/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8171\n",
            "Epoch 159/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8427\n",
            "Epoch 160/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8244\n",
            "Epoch 161/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8244\n",
            "Epoch 162/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8451\n",
            "Epoch 163/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8171\n",
            "Epoch 164/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8024\n",
            "Epoch 165/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8280\n",
            "Epoch 166/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8159\n",
            "Epoch 167/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8366\n",
            "Epoch 168/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3865 - accuracy: 0.8207\n",
            "Epoch 169/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8427\n",
            "Epoch 170/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8427\n",
            "Epoch 171/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8512\n",
            "Epoch 172/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8500\n",
            "Epoch 173/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8427\n",
            "Epoch 174/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8451\n",
            "Epoch 175/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8537\n",
            "Epoch 176/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8354\n",
            "Epoch 177/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8524\n",
            "Epoch 178/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.8512\n",
            "Epoch 179/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8427\n",
            "Epoch 180/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8341\n",
            "Epoch 181/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8110\n",
            "Epoch 182/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8256\n",
            "Epoch 183/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8439\n",
            "Epoch 184/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8085\n",
            "Epoch 185/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8415\n",
            "Epoch 186/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8598\n",
            "Epoch 187/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8280\n",
            "Epoch 188/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8573\n",
            "Epoch 189/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8512\n",
            "Epoch 190/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8585\n",
            "Epoch 191/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8341\n",
            "Epoch 192/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8244\n",
            "Epoch 193/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8159\n",
            "Epoch 194/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8329\n",
            "Epoch 195/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8512\n",
            "Epoch 196/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8476\n",
            "Epoch 197/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8463\n",
            "Epoch 198/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8061\n",
            "Epoch 199/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8476\n",
            "Epoch 200/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8512\n",
            "Epoch 201/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8427\n",
            "Epoch 202/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3775 - accuracy: 0.8451\n",
            "Epoch 203/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8317\n",
            "Epoch 204/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8415\n",
            "Epoch 205/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3776 - accuracy: 0.8415\n",
            "Epoch 206/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8439\n",
            "Epoch 207/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8220\n",
            "Epoch 208/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8305\n",
            "Epoch 209/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8439\n",
            "Epoch 210/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8476\n",
            "Epoch 211/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3829 - accuracy: 0.8341\n",
            "Epoch 212/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3806 - accuracy: 0.8451\n",
            "Epoch 213/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8476\n",
            "Epoch 214/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8537\n",
            "Epoch 215/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3723 - accuracy: 0.8463\n",
            "Epoch 216/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8341\n",
            "Epoch 217/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8549\n",
            "Epoch 218/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8268\n",
            "Epoch 219/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.8195\n",
            "Epoch 220/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3798 - accuracy: 0.8354\n",
            "Epoch 221/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8549\n",
            "Epoch 222/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8561\n",
            "Epoch 223/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8439\n",
            "Epoch 224/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3937 - accuracy: 0.8244\n",
            "Epoch 225/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3898 - accuracy: 0.8220\n",
            "Epoch 226/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8159\n",
            "Epoch 227/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8427\n",
            "Epoch 228/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.8512\n",
            "Epoch 229/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8451\n",
            "Epoch 230/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8439\n",
            "Epoch 231/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3889 - accuracy: 0.8268\n",
            "Epoch 232/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8207\n",
            "Epoch 233/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.8402\n",
            "Epoch 234/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8341\n",
            "Epoch 235/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8232\n",
            "Epoch 236/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8268\n",
            "Epoch 237/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8073\n",
            "Epoch 238/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8354\n",
            "Epoch 239/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8134\n",
            "Epoch 240/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8476\n",
            "Epoch 241/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8573\n",
            "Epoch 242/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8451\n",
            "Epoch 243/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8378\n",
            "Epoch 244/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8293\n",
            "Epoch 245/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8610\n",
            "Epoch 246/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8476\n",
            "Epoch 247/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8500\n",
            "Epoch 248/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8488\n",
            "Epoch 249/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8378\n",
            "Epoch 250/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8354\n",
            "Epoch 251/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8415\n",
            "Epoch 252/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8549\n",
            "Epoch 253/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8305\n",
            "Epoch 254/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8366\n",
            "Epoch 255/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8378\n",
            "Epoch 256/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8402\n",
            "Epoch 257/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8500\n",
            "Epoch 258/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8366\n",
            "Epoch 259/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8183\n",
            "Epoch 260/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8537\n",
            "Epoch 261/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8524\n",
            "Epoch 262/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8427\n",
            "Epoch 263/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8415\n",
            "Epoch 264/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8439\n",
            "Epoch 265/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8402\n",
            "Epoch 266/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8317\n",
            "Epoch 267/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8329\n",
            "Epoch 268/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8537\n",
            "Epoch 269/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8500\n",
            "Epoch 270/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8573\n",
            "Epoch 271/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8561\n",
            "Epoch 272/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8451\n",
            "Epoch 273/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8573\n",
            "Epoch 274/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8378\n",
            "Epoch 275/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8220\n",
            "Epoch 276/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8256\n",
            "Epoch 277/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8390\n",
            "Epoch 278/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8293\n",
            "Epoch 279/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8329\n",
            "Epoch 280/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8415\n",
            "Epoch 281/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8537\n",
            "Epoch 282/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8488\n",
            "Epoch 283/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8463\n",
            "Epoch 284/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8317\n",
            "Epoch 285/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8439\n",
            "Epoch 286/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8500\n",
            "Epoch 287/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8585\n",
            "Epoch 288/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3677 - accuracy: 0.8549\n",
            "Epoch 289/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8512\n",
            "Epoch 290/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8488\n",
            "Epoch 291/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8451\n",
            "Epoch 292/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3643 - accuracy: 0.8512\n",
            "Epoch 293/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8415\n",
            "Epoch 294/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8524\n",
            "Epoch 295/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8366\n",
            "Epoch 296/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8402\n",
            "Epoch 297/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8378\n",
            "Epoch 298/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8439\n",
            "Epoch 299/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8476\n",
            "Epoch 300/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8451\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bac9f587160>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_nn2=model.predict(X_test)\n",
        "y_pred_n3=[round(x[0]) for x in y_pred_nn2]\n",
        "print('The accuracy of the deep neural net is :', round(accuracy_score(y_test,y_pred_n3),2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iENrpM40Vm-K",
        "outputId": "ca7ca2e5-d3e6-49ac-ddf3-6d9b70d605f1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n",
            "The accuracy of the deep neural net is : 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_toZpu8SVt5i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}